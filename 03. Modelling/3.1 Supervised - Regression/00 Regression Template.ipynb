{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Linear Regression: $y = b0 + b1x1$  \n",
    "Multiple Linear Regression: $y = b0 + b1x1 + b2x2 + ... + bnxn$  \n",
    "Polynomial Linear Regression: $y = b0 + b1x1 + b2x1^2 + ... + bnx1^n$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTING DATA \n",
      "\n",
      "X: \n",
      "\n",
      "[[1.1 1 'New York']\n",
      " [1.3 1 'New York']\n",
      " [1.5 1 'California']\n",
      " [2.0 1 'New York']\n",
      " [2.2 1 'California']\n",
      " [2.9 2 'New York']\n",
      " [3.0 3 'California']\n",
      " [3.2 2 'Florida']\n",
      " [3.2 3 'Florida']\n",
      " [3.7 2 'New York']\n",
      " [3.9 3 'California']\n",
      " [4.0 2 'California']\n",
      " [4.0 3 'Florida']\n",
      " [4.1 3 'California']\n",
      " [4.5 3 'New York']\n",
      " [4.9 3 'New York']\n",
      " [5.1 3 'New York']\n",
      " [5.3 4 'California']\n",
      " [5.9 4 'Florida']\n",
      " [6.0 4 'California']\n",
      " [6.8 4 'Florida']\n",
      " [7.1 4 'New York']\n",
      " [7.9 4 'New York']\n",
      " [8.2 5 'California']\n",
      " [8.7 4 'California']\n",
      " [9.0 4 'New York']\n",
      " [9.5 5 'Florida']\n",
      " [9.6 5 'Florida']\n",
      " [10.3 5 'New York']\n",
      " [10.5 5 'New York']]\n",
      "\n",
      "y: \n",
      "\n",
      "[ 39343.  46205.  37731.  43525.  39891.  56642.  60150.  54445.  64445.\n",
      "  57189.  63218.  55794.  56957.  57081.  61111.  67938.  66029.  83088.\n",
      "  81363.  93940.  91738.  98273. 101302. 113812. 109431. 105582. 116969.\n",
      " 112635. 122391. 121872.]\n",
      "\n",
      " _______ \n",
      "\n",
      "MISSING DATA \n",
      "\n",
      "Missing values in each feature: \n",
      "\n",
      "YearsExperience    0\n",
      "Level              0\n",
      "State              0\n",
      "Salary             0\n",
      "dtype: int64\n",
      "\n",
      " _______ \n",
      "\n",
      "CATEGOTICAL ENCODING \n",
      "\n",
      "X before encoding: \n",
      "\n",
      " [[1.1 1 'New York']\n",
      " [1.3 1 'New York']\n",
      " [1.5 1 'California']\n",
      " [2.0 1 'New York']\n",
      " [2.2 1 'California']\n",
      " [2.9 2 'New York']\n",
      " [3.0 3 'California']\n",
      " [3.2 2 'Florida']\n",
      " [3.2 3 'Florida']\n",
      " [3.7 2 'New York']\n",
      " [3.9 3 'California']\n",
      " [4.0 2 'California']\n",
      " [4.0 3 'Florida']\n",
      " [4.1 3 'California']\n",
      " [4.5 3 'New York']\n",
      " [4.9 3 'New York']\n",
      " [5.1 3 'New York']\n",
      " [5.3 4 'California']\n",
      " [5.9 4 'Florida']\n",
      " [6.0 4 'California']\n",
      " [6.8 4 'Florida']\n",
      " [7.1 4 'New York']\n",
      " [7.9 4 'New York']\n",
      " [8.2 5 'California']\n",
      " [8.7 4 'California']\n",
      " [9.0 4 'New York']\n",
      " [9.5 5 'Florida']\n",
      " [9.6 5 'Florida']\n",
      " [10.3 5 'New York']\n",
      " [10.5 5 'New York']] \n",
      "\n",
      "\n",
      "X after encoding: \n",
      "\n",
      " [[0.0 1.0 1.1 1]\n",
      " [0.0 1.0 1.3 1]\n",
      " [0.0 0.0 1.5 1]\n",
      " [0.0 1.0 2.0 1]\n",
      " [0.0 0.0 2.2 1]\n",
      " [0.0 1.0 2.9 2]\n",
      " [0.0 0.0 3.0 3]\n",
      " [1.0 0.0 3.2 2]\n",
      " [1.0 0.0 3.2 3]\n",
      " [0.0 1.0 3.7 2]\n",
      " [0.0 0.0 3.9 3]\n",
      " [0.0 0.0 4.0 2]\n",
      " [1.0 0.0 4.0 3]\n",
      " [0.0 0.0 4.1 3]\n",
      " [0.0 1.0 4.5 3]\n",
      " [0.0 1.0 4.9 3]\n",
      " [0.0 1.0 5.1 3]\n",
      " [0.0 0.0 5.3 4]\n",
      " [1.0 0.0 5.9 4]\n",
      " [0.0 0.0 6.0 4]\n",
      " [1.0 0.0 6.8 4]\n",
      " [0.0 1.0 7.1 4]\n",
      " [0.0 1.0 7.9 4]\n",
      " [0.0 0.0 8.2 5]\n",
      " [0.0 0.0 8.7 4]\n",
      " [0.0 1.0 9.0 4]\n",
      " [1.0 0.0 9.5 5]\n",
      " [1.0 0.0 9.6 5]\n",
      " [0.0 1.0 10.3 5]\n",
      " [0.0 1.0 10.5 5]] \n",
      "\n",
      "\n",
      "X mapping (col names): \n",
      "\n",
      " ['encoder__x0_California', 'encoder__x0_Florida', 'encoder__x0_New York'] \n",
      "\n",
      "\n",
      "SPLITTING DATA \n",
      "\n",
      "Training set size set at =  0.8 \n",
      "Testing set size set at =  0.2\n",
      "\n",
      "Number of samples in training set =  24\n",
      "\n",
      "Number of samples in testing set =  6\n",
      "\n",
      "\n",
      "X Train =  [[1.0 0.0 9.6 5]\n",
      " [0.0 0.0 4.0 2]\n",
      " [0.0 0.0 5.3 4]\n",
      " [0.0 1.0 7.9 4]\n",
      " [0.0 1.0 2.9 2]\n",
      " [0.0 1.0 5.1 3]\n",
      " [1.0 0.0 3.2 3]\n",
      " [0.0 1.0 4.5 3]\n",
      " [0.0 0.0 8.2 5]\n",
      " [1.0 0.0 6.8 4]\n",
      " [0.0 1.0 1.3 1]\n",
      " [0.0 1.0 10.5 5]\n",
      " [0.0 0.0 3.0 3]\n",
      " [0.0 0.0 2.2 1]\n",
      " [1.0 0.0 5.9 4]\n",
      " [0.0 0.0 6.0 4]\n",
      " [0.0 1.0 3.7 2]\n",
      " [1.0 0.0 3.2 2]\n",
      " [0.0 1.0 9.0 4]\n",
      " [0.0 1.0 2.0 1]\n",
      " [0.0 1.0 1.1 1]\n",
      " [0.0 1.0 7.1 4]\n",
      " [0.0 1.0 4.9 3]\n",
      " [1.0 0.0 4.0 3]]\n",
      "\n",
      "X Test =  [[0.0 0.0 1.5 1]\n",
      " [0.0 1.0 10.3 5]\n",
      " [0.0 0.0 4.1 3]\n",
      " [0.0 0.0 3.9 3]\n",
      " [1.0 0.0 9.5 5]\n",
      " [0.0 0.0 8.7 4]]\n",
      "\n",
      "y Train =  [112635.  55794.  83088. 101302.  56642.  66029.  64445.  61111. 113812.\n",
      "  91738.  46205. 121872.  60150.  39891.  81363.  93940.  57189.  54445.\n",
      " 105582.  43525.  39343.  98273.  67938.  56957.]\n",
      "\n",
      "y Test =  [ 37731. 122391.  57081.  63218. 116969. 109431.]\n",
      "\n",
      " _______ \n",
      "\n",
      "FEATURE SCALING\n",
      "\n",
      "\n",
      "X Train =  [[ 1.73205081 -1.          1.75832984  1.53706436]\n",
      " [-0.57735027 -1.         -0.40973925 -0.81758743]\n",
      " [-0.57735027 -1.          0.09356251  0.75218043]\n",
      " [-0.57735027  1.          1.10016601  0.75218043]\n",
      " [-0.57735027  1.         -0.83560996 -0.81758743]\n",
      " [-0.57735027  1.          0.01613147 -0.0327035 ]\n",
      " [ 1.73205081 -1.         -0.7194634  -0.0327035 ]\n",
      " [-0.57735027  1.         -0.21616165 -0.0327035 ]\n",
      " [-0.57735027 -1.          1.21631257  1.53706436]\n",
      " [ 1.73205081 -1.          0.6742953   0.75218043]\n",
      " [-0.57735027  1.         -1.45505827 -1.60247135]\n",
      " [-0.57735027  1.          2.10676952  1.53706436]\n",
      " [-0.57735027 -1.         -0.79689444 -0.0327035 ]\n",
      " [-0.57735027 -1.         -1.1066186  -1.60247135]\n",
      " [ 1.73205081 -1.          0.32585562  0.75218043]\n",
      " [-0.57735027 -1.          0.36457114  0.75218043]\n",
      " [-0.57735027  1.         -0.52588581 -0.81758743]\n",
      " [ 1.73205081 -1.         -0.7194634  -0.81758743]\n",
      " [-0.57735027  1.          1.52603672  0.75218043]\n",
      " [-0.57735027  1.         -1.18404964 -1.60247135]\n",
      " [-0.57735027  1.         -1.53248931 -1.60247135]\n",
      " [-0.57735027  1.          0.79044186  0.75218043]\n",
      " [-0.57735027  1.         -0.06129957 -0.0327035 ]\n",
      " [ 1.73205081 -1.         -0.40973925 -0.0327035 ]]\n",
      "\n",
      "X Test =  [[-0.57735027 -1.         -1.37762723 -1.60247135]\n",
      " [-0.57735027  1.          2.02933848  1.53706436]\n",
      " [-0.57735027 -1.         -0.37102373 -0.0327035 ]\n",
      " [-0.57735027 -1.         -0.44845477 -0.0327035 ]\n",
      " [ 1.73205081 -1.          1.71961432  1.53706436]\n",
      " [-0.57735027 -1.          1.40989017  0.75218043]]\n",
      "\n",
      "y Train =  [[ 1.56283548]\n",
      " [-0.72970392]\n",
      " [ 0.37113122]\n",
      " [ 1.1057473 ]\n",
      " [-0.69550196]\n",
      " [-0.31690082]\n",
      " [-0.3807875 ]\n",
      " [-0.51525604]\n",
      " [ 1.61030683]\n",
      " [ 0.72000731]\n",
      " [-1.11645222]\n",
      " [ 1.93538674]\n",
      " [-0.55401557]\n",
      " [-1.3711116 ]\n",
      " [ 0.30155767]\n",
      " [ 0.80881947]\n",
      " [-0.67344009]\n",
      " [-0.78411245]\n",
      " [ 1.27837039]\n",
      " [-1.22454331]\n",
      " [-1.39321381]\n",
      " [ 0.98358017]\n",
      " [-0.23990609]\n",
      " [-0.68279723]]\n",
      "\n",
      "y Test =  [[-1.45822979]\n",
      " [ 1.95631931]\n",
      " [-0.677796  ]\n",
      " [-0.43027547]\n",
      " [ 1.73763652]\n",
      " [ 1.43361016]]\n",
      "\n",
      " _______ \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saspeslagh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\saspeslagh\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Regression Template \n",
    "# for labelled continuous data\n",
    "\n",
    "# Includes:\n",
    "# - Data Preprocessing Template\n",
    "\n",
    "# Created by Sofie Aspeslagh \n",
    "\n",
    "## ------- How to use ------- ##\n",
    "\n",
    "# Any steps the need to be done within the code with be annotated with:\n",
    "# ----->>\n",
    "\n",
    "# Follow the steps below to \n",
    "# Step 1 - ADD STEPS\n",
    "\n",
    "\n",
    "# Simple Linear Regression\n",
    "\n",
    "\n",
    "## ------- Import libraries and data ------- ##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ----->> put addition libraries here \n",
    "\n",
    "lst = [[1.1,'Business Analyst',1,'New York',39343.00],\n",
    "       [1.3,'Business Analyst',1,'New York',46205.00],\n",
    "       [1.5,'Business Analyst',1,'California',37731.00],\n",
    "       [2.0,'Business Analyst',1,'New York',43525.00],\n",
    "       [2.2,'Business Analyst',1,'California',39891.00],\n",
    "       [2.9,'Junior Consultant',2,'New York',56642.00],\n",
    "       [3.0,'Senior Consultant',3,'California',60150.00],\n",
    "       [3.2,'Junior Consultant',2,'Florida',54445.00],\n",
    "       [3.2,'Senior Consultant',3,'Florida',64445.00],\n",
    "       [3.7,'Junior Consultant',2,'New York',57189.00],\n",
    "       [3.9,'Senior Consultant',3,'California',63218.00],\n",
    "       [4.0,'Junior Consultant',2,'California',55794.00],\n",
    "       [4.0,'Senior Consultant',3,'Florida',56957.00],\n",
    "       [4.1,'Senior Consultant',3,'California',57081.00],\n",
    "       [4.5,'Senior Consultant',3,'New York',61111.00],\n",
    "       [4.9,'Senior Consultant',3,'New York',67938.00],\n",
    "       [5.1,'Senior Consultant',3,'New York',66029.00],\n",
    "       [5.3,'Manager',4,'California',83088.00],\n",
    "       [5.9,'Manager',4,'Florida',81363.00],\n",
    "       [6.0,'Manager',4,'California',93940.00],\n",
    "       [6.8,'Manager',4,'Florida',91738.00],\n",
    "       [7.1,'Manager',4,'New York',98273.00],\n",
    "       [7.9,'Manager',4,'New York',101302.00],\n",
    "       [8.2,'Country Manager',5,'California',113812.00],\n",
    "       [8.7,'Manager',4,'California',109431.00],\n",
    "       [9.0,'Manager',4,'New York',105582.00],\n",
    "       [9.5,'Country Manager',5,'Florida',116969.00],\n",
    "       [9.6,'Country Manager',5,'Florida',112635.00],\n",
    "       [10.3,'Country Manager',5,'New York',122391.00],\n",
    "       [10.5,'Country Manager',5,'New York',121872.00]]\n",
    "\n",
    "lst_plr = [[1,45000],\n",
    "         [2,50000],\n",
    "         [3,60000],\n",
    "         [4,80000],\n",
    "         [5,110000],\n",
    "         [6,150000],\n",
    "         [7,200000],\n",
    "         [8,300000],\n",
    "         [9,500000],\n",
    "         [10,1000000]]\n",
    "\n",
    "df_plr = pd.DataFrame(lst_plr, columns =['Level','Salary'])\n",
    "\n",
    "df = pd.DataFrame(lst, columns =['YearsExperience', 'Position', 'Level', 'State','Salary'])\n",
    "# ----->> remove lst and import data as df i.e df = pd.read_csv('filename.csv')\n",
    "\n",
    "# drop position as it is the same as level\n",
    "df = df.drop(columns=\"Position\")\n",
    "\n",
    "# set X as all independent variables\n",
    "X = df.iloc[:,:-1].values\n",
    "\n",
    "# set y as dependent variable\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "# set X and y for plr data\n",
    "X_plr = df_plr.iloc[:,:-1].values\n",
    "y_plr = df_plr.iloc[:,-1].values\n",
    "\n",
    "print('IMPORTING DATA \\n')\n",
    "print('X: \\n')\n",
    "print(X)\n",
    "print('\\ny: \\n')\n",
    "print(y)\n",
    "print('\\n','_'*7,'\\n')\n",
    "# ----->> check that X and y are correct\n",
    "\n",
    "####### PREPROCESSING\n",
    "\n",
    "## ------- Detecting missing values ------- ##\n",
    "\n",
    "# detect any NaN values - keep in mind missing values may be represented in various ways. \n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "print('MISSING DATA \\n')\n",
    "print('Missing values in each feature: \\n')\n",
    "print(missing_data)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "# ## ------- Replace missing values by the Mean ------- ##\n",
    "\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# print('REPLACING MISSING DATA \\n')\n",
    "# print('Check X before imputer: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# # create imputer object - for more info use help(SimpleImputer)\n",
    "# imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "\n",
    "# # fit object to data - take only the cols that have missing data\n",
    "# imputer = imputer.fit(X[:, 1:3])\n",
    "\n",
    "# # replace nan values\n",
    "# X[:,1:3] = imputer.transform(X[:,1:3])\n",
    "\n",
    "# print('Check X after imputer: \\n\\n', X)\n",
    "# print('\\n','_'*7,'\\n')\n",
    "\n",
    "\n",
    "# ## ------- Categorical encoding ------- ##\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "print('CATEGOTICAL ENCODING \\n')\n",
    "print('X before encoding: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# Set Categorical data index\n",
    "cat_data_index = 2\n",
    "\n",
    "# Create Column Transformer object for multi-categoical \n",
    "columntransformer = ColumnTransformer([('encoder', OneHotEncoder(), [cat_data_index])], remainder='passthrough')\n",
    "\n",
    "# take a copy for mapping purposes \n",
    "X_names = X.copy()\n",
    "\n",
    "# fit to data\n",
    "X = columntransformer.fit_transform(X) \n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "\n",
    "# need to use drop if you want to get feature names \n",
    "columntransformer_names = ColumnTransformer([('encoder', OneHotEncoder(), [cat_data_index])], remainder='drop')\n",
    "X_names = columntransformer_names.fit_transform(X_names)\n",
    "X_mapping_vals = columntransformer_names.get_feature_names()\n",
    "\n",
    "print('X after encoding: \\n\\n', X, '\\n\\n')\n",
    "print('X mapping (col names): \\n\\n', X_mapping_vals, '\\n\\n')\n",
    "\n",
    "\n",
    "# print('y before encoding: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# # label encoder create object for binary categoical features\n",
    "# labelencoder_y = LabelEncoder()\n",
    "\n",
    "# # fit object to the data and replace categorical data\n",
    "# y  = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# # get mapping of features \n",
    "# y_mapping_vals = dict(zip(labelencoder_y.classes_, labelencoder_y.transform(labelencoder_y.classes_)))\n",
    "\n",
    "# print('y after encoding: \\n\\n', y, '\\n\\n')\n",
    "# print('y mapping: \\n\\n', y_mapping_vals, '\\n')\n",
    "# print('\\n','_'*7,'\\n')\n",
    "\n",
    "## ------- Splitting into Training and Test set ------- ##\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set the test size\n",
    "test_split = 0.2\n",
    "\n",
    "# random_state is set to ensure that same outcome each time. Would work fine without this\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, random_state = 0)\n",
    "\n",
    "print('SPLITTING DATA \\n')\n",
    "print('Training set size set at = ',1-test_split,'\\nTesting set size set at = ',test_split)\n",
    "print('\\nNumber of samples in training set = ', len(X_train))\n",
    "print('\\nNumber of samples in testing set = ', len(X_test))\n",
    "\n",
    "print('\\n\\nX Train = ', X_train)\n",
    "print('\\nX Test = ', X_test)\n",
    "print('\\ny Train = ', y_train)\n",
    "print('\\ny Test = ', y_test)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "## ------- Feature Scaling ------- ##\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Make scaling object using Standardization\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# Fit and transform to training data\n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "\n",
    "# use the same fit as the training set and transform the test set\n",
    "X_test = sc_X.transform(X_test) \n",
    "\n",
    "\n",
    "# Y scaling only needs to be done for regression not classification \n",
    "sc_y = StandardScaler()\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "y_train = sc_y.fit_transform(y_train)\n",
    "y_test = sc_y.transform(y_test)\n",
    "\n",
    "print('FEATURE SCALING\\n')\n",
    "print('\\nX Train = ', X_train)\n",
    "print('\\nX Test = ', X_test)\n",
    "print('\\ny Train = ', y_train)\n",
    "print('\\ny Test = ', y_test)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "####### MODELS\n",
    "\n",
    "## ------- Simple Linear Regression -------\n",
    "\n",
    "# # Remove all other variables apart from years experience for simple regression example\n",
    "# ##------- >> REMEMBER TO DELETE IF NOT NEEDED\n",
    "# X_train = X_train[:,3].reshape(-1, 1) \n",
    "# X_test = X_test[:,3].reshape(-1, 1)\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# regressor = LinearRegression()\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# # Predicting the Test set results\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# # plots\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Visualising the Training set results\n",
    "# plt.scatter(X_train, y_train, color = 'red')\n",
    "# plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "# plt.title('Salary vs Experience (Training set)')\n",
    "# plt.xlabel('Years of Experience')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "# # Visualising the Test set results\n",
    "# plt.scatter(X_test, y_test, color = 'red')\n",
    "# plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "# plt.title('Salary vs Experience (Test set)')\n",
    "# plt.xlabel('Years of Experience')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## ------- Multiple Linear Regression -------\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# regressor = LinearRegression()\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# # Predicting the Test set results\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# # transform numbers back (can double check with origianl y_test)\n",
    "# y_test_end = sc_y.inverse_transform(y_test)\n",
    "# y_pred_end = sc_y.inverse_transform(y_pred)\n",
    "\n",
    "# print(' ------- Multiple Linear Regression ------- \\n')\n",
    "# print('Real: \\n', y_test_end, '\\n\\nPredicted: \\n',y_pred_end)\n",
    "\n",
    "\n",
    "\n",
    "## ------- Polynomial Linear Regression ----- ##\n",
    "\n",
    "# # not bothering with splitting the data for this example nor does it need to be stadardised. \n",
    "\n",
    "# # Fitting Linear Regression to the dataset\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# lin_reg = LinearRegression()\n",
    "# lin_reg.fit(X_plr, y_plr)\n",
    "\n",
    "# # Fitting Polynomial Regression to the dataset\n",
    "# from sklearn.preprocessing import PolynomialFeatures\n",
    "# poly_reg = PolynomialFeatures(degree = 4)\n",
    "# X_poly = poly_reg.fit_transform(X_plr)\n",
    "# poly_reg.fit(X_poly, y_plr)\n",
    "# lin_reg_2 = LinearRegression()\n",
    "# lin_reg_2.fit(X_poly, y_plr)\n",
    "\n",
    "# # Visualising the Linear Regression results\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.scatter(X_plr, y_plr, color = 'red')\n",
    "# plt.plot(X_plr, lin_reg.predict(X_plr), color = 'blue')\n",
    "# plt.title('Truth or Bluff (Linear Regression)')\n",
    "# plt.xlabel('Position level')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "# # Visualising the Polynomial Regression results\n",
    "# plt.scatter(X_plr, y_plr, color = 'red')\n",
    "# plt.plot(X_plr, lin_reg_2.predict(poly_reg.fit_transform(X_plr)), color = 'blue')\n",
    "# plt.title('Truth or Bluff (Polynomial Regression)')\n",
    "# plt.xlabel('Position level')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "# # Visualising the Polynomial Regression results (for higher resolution and smoother curve)\n",
    "# X_grid = np.arange(min(X_plr), max(X_plr), 0.1)\n",
    "# X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "# plt.scatter(X_plr, y_plr, color = 'red')\n",
    "# plt.plot(X_grid, lin_reg_2.predict(poly_reg.fit_transform(X_grid)), color = 'blue')\n",
    "# plt.title('Truth or Bluff (Polynomial Regression)')\n",
    "# plt.xlabel('Position level')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "## ------- SVR ------- ##\n",
    "X_plr = X_plr.reshape(-1, 1) \n",
    "y_plr = y_plr.reshape(-1, 1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Make scaling object using Standardization\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# Fit and transform to training data\n",
    "X_train = sc_X.fit_transform(X_plr) \n",
    "\n",
    "# Y scaling only needs to be done for regression not classification \n",
    "sc_y = StandardScaler()\n",
    "y_plr = sc_y.fit_transform(y_plr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X_plr)\n",
    "y = sc_y.fit_transform(y_plr)\n",
    "\n",
    "# Fitting SVR to the dataset\n",
    "from sklearn.svm import SVR\n",
    "regressor = SVR(kernel = 'rbf')\n",
    "regressor.fit(X_plr, y_plr)\n",
    "\n",
    "# # Predicting a new result\n",
    "# y_pred = regressor.predict(6.5)\n",
    "# y_pred = sc_y.inverse_transform(y_pred)\n",
    "\n",
    "# Visualising the SVR results\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_plr, y_plr, color = 'red')\n",
    "plt.plot(X_plr, regressor.predict(X_plr), color = 'blue')\n",
    "plt.title('Truth or Bluff (SVR)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()\n",
    "\n",
    "# Visualising the SVR results (for higher resolution and smoother curve)\n",
    "X_grid = np.arange(min(X_plr), max(X_plr), 0.01) # choice of 0.01 instead of 0.1 step because the data is feature scaled\n",
    "X_grid = X_grid.reshape((len(X_grid), 1))\n",
    "plt.scatter(X_plr, y_plr, color = 'red')\n",
    "plt.plot(X_grid, regressor.predict(X_grid), color = 'blue')\n",
    "plt.title('Truth or Bluff (SVR)')\n",
    "plt.xlabel('Position level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
