{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTING DATA \n",
      "\n",
      "X: \n",
      "\n",
      "[[1.1 1 'New York']\n",
      " [1.3 1 'New York']\n",
      " [1.5 1 'California']\n",
      " [2.0 1 'New York']\n",
      " [2.2 1 'California']\n",
      " [2.9 2 'New York']\n",
      " [3.0 3 'California']\n",
      " [3.2 2 'Florida']\n",
      " [3.2 3 'Florida']\n",
      " [3.7 2 'New York']\n",
      " [3.9 3 'California']\n",
      " [4.0 2 'California']\n",
      " [4.0 3 'Florida']\n",
      " [4.1 3 'California']\n",
      " [4.5 3 'New York']\n",
      " [4.9 3 'New York']\n",
      " [5.1 3 'New York']\n",
      " [5.3 4 'California']\n",
      " [5.9 4 'Florida']\n",
      " [6.0 4 'California']\n",
      " [6.8 4 'Florida']\n",
      " [7.1 4 'New York']\n",
      " [7.9 4 'New York']\n",
      " [8.2 5 'California']\n",
      " [8.7 4 'California']\n",
      " [9.0 4 'New York']\n",
      " [9.5 5 'Florida']\n",
      " [9.6 5 'Florida']\n",
      " [10.3 5 'New York']\n",
      " [10.5 5 'New York']]\n",
      "\n",
      "y: \n",
      "\n",
      "[ 39343.  46205.  37731.  43525.  39891.  56642.  60150.  54445.  64445.\n",
      "  57189.  63218.  55794.  56957.  57081.  61111.  67938.  66029.  83088.\n",
      "  81363.  93940.  91738.  98273. 101302. 113812. 109431. 105582. 116969.\n",
      " 112635. 122391. 121872.]\n",
      "\n",
      " _______ \n",
      "\n",
      "MISSING DATA \n",
      "\n",
      "Missing values in each feature: \n",
      "\n",
      "YearsExperience    0\n",
      "Level              0\n",
      "State              0\n",
      "Salary             0\n",
      "dtype: int64\n",
      "\n",
      " _______ \n",
      "\n",
      "CATEGOTICAL ENCODING \n",
      "\n",
      "X before encoding: \n",
      "\n",
      " [[1.1 1 'New York']\n",
      " [1.3 1 'New York']\n",
      " [1.5 1 'California']\n",
      " [2.0 1 'New York']\n",
      " [2.2 1 'California']\n",
      " [2.9 2 'New York']\n",
      " [3.0 3 'California']\n",
      " [3.2 2 'Florida']\n",
      " [3.2 3 'Florida']\n",
      " [3.7 2 'New York']\n",
      " [3.9 3 'California']\n",
      " [4.0 2 'California']\n",
      " [4.0 3 'Florida']\n",
      " [4.1 3 'California']\n",
      " [4.5 3 'New York']\n",
      " [4.9 3 'New York']\n",
      " [5.1 3 'New York']\n",
      " [5.3 4 'California']\n",
      " [5.9 4 'Florida']\n",
      " [6.0 4 'California']\n",
      " [6.8 4 'Florida']\n",
      " [7.1 4 'New York']\n",
      " [7.9 4 'New York']\n",
      " [8.2 5 'California']\n",
      " [8.7 4 'California']\n",
      " [9.0 4 'New York']\n",
      " [9.5 5 'Florida']\n",
      " [9.6 5 'Florida']\n",
      " [10.3 5 'New York']\n",
      " [10.5 5 'New York']] \n",
      "\n",
      "\n",
      "X after encoding: \n",
      "\n",
      " [[0.0 1.0 1.1 1]\n",
      " [0.0 1.0 1.3 1]\n",
      " [0.0 0.0 1.5 1]\n",
      " [0.0 1.0 2.0 1]\n",
      " [0.0 0.0 2.2 1]\n",
      " [0.0 1.0 2.9 2]\n",
      " [0.0 0.0 3.0 3]\n",
      " [1.0 0.0 3.2 2]\n",
      " [1.0 0.0 3.2 3]\n",
      " [0.0 1.0 3.7 2]\n",
      " [0.0 0.0 3.9 3]\n",
      " [0.0 0.0 4.0 2]\n",
      " [1.0 0.0 4.0 3]\n",
      " [0.0 0.0 4.1 3]\n",
      " [0.0 1.0 4.5 3]\n",
      " [0.0 1.0 4.9 3]\n",
      " [0.0 1.0 5.1 3]\n",
      " [0.0 0.0 5.3 4]\n",
      " [1.0 0.0 5.9 4]\n",
      " [0.0 0.0 6.0 4]\n",
      " [1.0 0.0 6.8 4]\n",
      " [0.0 1.0 7.1 4]\n",
      " [0.0 1.0 7.9 4]\n",
      " [0.0 0.0 8.2 5]\n",
      " [0.0 0.0 8.7 4]\n",
      " [0.0 1.0 9.0 4]\n",
      " [1.0 0.0 9.5 5]\n",
      " [1.0 0.0 9.6 5]\n",
      " [0.0 1.0 10.3 5]\n",
      " [0.0 1.0 10.5 5]] \n",
      "\n",
      "\n",
      "X mapping (col names): \n",
      "\n",
      " ['encoder__x0_California', 'encoder__x0_Florida', 'encoder__x0_New York'] \n",
      "\n",
      "\n",
      "SPLITTING DATA \n",
      "\n",
      "Training set size set at =  0.8 \n",
      "Testing set size set at =  0.2\n",
      "\n",
      "Number of samples in training set =  24\n",
      "\n",
      "Number of samples in testing set =  6\n",
      "\n",
      "\n",
      "X Train =  [[1.0 0.0 9.6 5]\n",
      " [0.0 0.0 4.0 2]\n",
      " [0.0 0.0 5.3 4]\n",
      " [0.0 1.0 7.9 4]\n",
      " [0.0 1.0 2.9 2]\n",
      " [0.0 1.0 5.1 3]\n",
      " [1.0 0.0 3.2 3]\n",
      " [0.0 1.0 4.5 3]\n",
      " [0.0 0.0 8.2 5]\n",
      " [1.0 0.0 6.8 4]\n",
      " [0.0 1.0 1.3 1]\n",
      " [0.0 1.0 10.5 5]\n",
      " [0.0 0.0 3.0 3]\n",
      " [0.0 0.0 2.2 1]\n",
      " [1.0 0.0 5.9 4]\n",
      " [0.0 0.0 6.0 4]\n",
      " [0.0 1.0 3.7 2]\n",
      " [1.0 0.0 3.2 2]\n",
      " [0.0 1.0 9.0 4]\n",
      " [0.0 1.0 2.0 1]\n",
      " [0.0 1.0 1.1 1]\n",
      " [0.0 1.0 7.1 4]\n",
      " [0.0 1.0 4.9 3]\n",
      " [1.0 0.0 4.0 3]]\n",
      "\n",
      "X Test =  [[0.0 0.0 1.5 1]\n",
      " [0.0 1.0 10.3 5]\n",
      " [0.0 0.0 4.1 3]\n",
      " [0.0 0.0 3.9 3]\n",
      " [1.0 0.0 9.5 5]\n",
      " [0.0 0.0 8.7 4]]\n",
      "\n",
      "y Train =  [112635.  55794.  83088. 101302.  56642.  66029.  64445.  61111. 113812.\n",
      "  91738.  46205. 121872.  60150.  39891.  81363.  93940.  57189.  54445.\n",
      " 105582.  43525.  39343.  98273.  67938.  56957.]\n",
      "\n",
      "y Test =  [ 37731. 122391.  57081.  63218. 116969. 109431.]\n",
      "\n",
      " _______ \n",
      "\n",
      "FEATURE SCALING\n",
      "\n",
      "\n",
      "X Train =  [[ 1.73205081 -1.          1.75832984  1.53706436]\n",
      " [-0.57735027 -1.         -0.40973925 -0.81758743]\n",
      " [-0.57735027 -1.          0.09356251  0.75218043]\n",
      " [-0.57735027  1.          1.10016601  0.75218043]\n",
      " [-0.57735027  1.         -0.83560996 -0.81758743]\n",
      " [-0.57735027  1.          0.01613147 -0.0327035 ]\n",
      " [ 1.73205081 -1.         -0.7194634  -0.0327035 ]\n",
      " [-0.57735027  1.         -0.21616165 -0.0327035 ]\n",
      " [-0.57735027 -1.          1.21631257  1.53706436]\n",
      " [ 1.73205081 -1.          0.6742953   0.75218043]\n",
      " [-0.57735027  1.         -1.45505827 -1.60247135]\n",
      " [-0.57735027  1.          2.10676952  1.53706436]\n",
      " [-0.57735027 -1.         -0.79689444 -0.0327035 ]\n",
      " [-0.57735027 -1.         -1.1066186  -1.60247135]\n",
      " [ 1.73205081 -1.          0.32585562  0.75218043]\n",
      " [-0.57735027 -1.          0.36457114  0.75218043]\n",
      " [-0.57735027  1.         -0.52588581 -0.81758743]\n",
      " [ 1.73205081 -1.         -0.7194634  -0.81758743]\n",
      " [-0.57735027  1.          1.52603672  0.75218043]\n",
      " [-0.57735027  1.         -1.18404964 -1.60247135]\n",
      " [-0.57735027  1.         -1.53248931 -1.60247135]\n",
      " [-0.57735027  1.          0.79044186  0.75218043]\n",
      " [-0.57735027  1.         -0.06129957 -0.0327035 ]\n",
      " [ 1.73205081 -1.         -0.40973925 -0.0327035 ]]\n",
      "\n",
      "X Test =  [[-0.57735027 -1.         -1.37762723 -1.60247135]\n",
      " [-0.57735027  1.          2.02933848  1.53706436]\n",
      " [-0.57735027 -1.         -0.37102373 -0.0327035 ]\n",
      " [-0.57735027 -1.         -0.44845477 -0.0327035 ]\n",
      " [ 1.73205081 -1.          1.71961432  1.53706436]\n",
      " [-0.57735027 -1.          1.40989017  0.75218043]]\n",
      "\n",
      "y Train =  [[ 1.56283548]\n",
      " [-0.72970392]\n",
      " [ 0.37113122]\n",
      " [ 1.1057473 ]\n",
      " [-0.69550196]\n",
      " [-0.31690082]\n",
      " [-0.3807875 ]\n",
      " [-0.51525604]\n",
      " [ 1.61030683]\n",
      " [ 0.72000731]\n",
      " [-1.11645222]\n",
      " [ 1.93538674]\n",
      " [-0.55401557]\n",
      " [-1.3711116 ]\n",
      " [ 0.30155767]\n",
      " [ 0.80881947]\n",
      " [-0.67344009]\n",
      " [-0.78411245]\n",
      " [ 1.27837039]\n",
      " [-1.22454331]\n",
      " [-1.39321381]\n",
      " [ 0.98358017]\n",
      " [-0.23990609]\n",
      " [-0.68279723]]\n",
      "\n",
      "y Test =  [[-1.45822979]\n",
      " [ 1.95631931]\n",
      " [-0.677796  ]\n",
      " [-0.43027547]\n",
      " [ 1.73763652]\n",
      " [ 1.43361016]]\n",
      "\n",
      " _______ \n",
      "\n",
      " ------- Multiple Linear Regression ------- \n",
      "\n",
      "Real = \n",
      " [[ 37731.]\n",
      " [122391.]\n",
      " [ 57081.]\n",
      " [ 63218.]\n",
      " [116969.]\n",
      " [109431.]] \n",
      "\n",
      "Predicted: \n",
      " [[ 43751.92637206]\n",
      " [121630.75971414]\n",
      " [ 68057.76132616]\n",
      " [ 66188.08171431]\n",
      " [114791.51214005]\n",
      " [111060.39239882]]\n"
     ]
    }
   ],
   "source": [
    "# Regression Template \n",
    "# for labelled continuous data\n",
    "\n",
    "# Includes:\n",
    "# - Data Preprocessing Template\n",
    "\n",
    "# Created by Sofie Aspeslagh \n",
    "\n",
    "## ------- How to use ------- ##\n",
    "\n",
    "# Any steps the need to be done within the code with be annotated with:\n",
    "# ----->>\n",
    "\n",
    "# Follow the steps below to \n",
    "# Step 1 - ADD STEPS\n",
    "\n",
    "\n",
    "# Simple Linear Regression\n",
    "\n",
    "\n",
    "## ------- Import libraries and data ------- ##\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# ----->> put addition libraries here \n",
    "\n",
    "lst = [[1.1,'Business Analyst',1,'New York',39343.00],\n",
    "       [1.3,'Business Analyst',1,'New York',46205.00],\n",
    "       [1.5,'Business Analyst',1,'California',37731.00],\n",
    "       [2.0,'Business Analyst',1,'New York',43525.00],\n",
    "       [2.2,'Business Analyst',1,'California',39891.00],\n",
    "       [2.9,'Junior Consultant',2,'New York',56642.00],\n",
    "       [3.0,'Senior Consultant',3,'California',60150.00],\n",
    "       [3.2,'Junior Consultant',2,'Florida',54445.00],\n",
    "       [3.2,'Senior Consultant',3,'Florida',64445.00],\n",
    "       [3.7,'Junior Consultant',2,'New York',57189.00],\n",
    "       [3.9,'Senior Consultant',3,'California',63218.00],\n",
    "       [4.0,'Junior Consultant',2,'California',55794.00],\n",
    "       [4.0,'Senior Consultant',3,'Florida',56957.00],\n",
    "       [4.1,'Senior Consultant',3,'California',57081.00],\n",
    "       [4.5,'Senior Consultant',3,'New York',61111.00],\n",
    "       [4.9,'Senior Consultant',3,'New York',67938.00],\n",
    "       [5.1,'Senior Consultant',3,'New York',66029.00],\n",
    "       [5.3,'Manager',4,'California',83088.00],\n",
    "       [5.9,'Manager',4,'Florida',81363.00],\n",
    "       [6.0,'Manager',4,'California',93940.00],\n",
    "       [6.8,'Manager',4,'Florida',91738.00],\n",
    "       [7.1,'Manager',4,'New York',98273.00],\n",
    "       [7.9,'Manager',4,'New York',101302.00],\n",
    "       [8.2,'Country Manager',5,'California',113812.00],\n",
    "       [8.7,'Manager',4,'California',109431.00],\n",
    "       [9.0,'Manager',4,'New York',105582.00],\n",
    "       [9.5,'Country Manager',5,'Florida',116969.00],\n",
    "       [9.6,'Country Manager',5,'Florida',112635.00],\n",
    "       [10.3,'Country Manager',5,'New York',122391.00],\n",
    "       [10.5,'Country Manager',5,'New York',121872.00]]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(lst, columns =['YearsExperience', 'Position', 'Level', 'State','Salary'])\n",
    "# ----->> remove lst and import data as df i.e df = pd.read_csv('filename.csv')\n",
    "\n",
    "# drop position as it is the same as level\n",
    "df = df.drop(columns=\"Position\")\n",
    "\n",
    "# set X as all independent variables\n",
    "X = df.iloc[:,:-1].values\n",
    "\n",
    "# set y as dependent variable\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "print('IMPORTING DATA \\n')\n",
    "print('X: \\n')\n",
    "print(X)\n",
    "print('\\ny: \\n')\n",
    "print(y)\n",
    "print('\\n','_'*7,'\\n')\n",
    "# ----->> check that X and y are correct\n",
    "\n",
    "####### PREPROCESSING\n",
    "\n",
    "## ------- Detecting missing values ------- ##\n",
    "\n",
    "# detect any NaN values - keep in mind missing values may be represented in various ways. \n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "print('MISSING DATA \\n')\n",
    "print('Missing values in each feature: \\n')\n",
    "print(missing_data)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "# ## ------- Replace missing values by the Mean ------- ##\n",
    "\n",
    "# from sklearn.impute import SimpleImputer\n",
    "\n",
    "# print('REPLACING MISSING DATA \\n')\n",
    "# print('Check X before imputer: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# # create imputer object - for more info use help(SimpleImputer)\n",
    "# imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "\n",
    "# # fit object to data - take only the cols that have missing data\n",
    "# imputer = imputer.fit(X[:, 1:3])\n",
    "\n",
    "# # replace nan values\n",
    "# X[:,1:3] = imputer.transform(X[:,1:3])\n",
    "\n",
    "# print('Check X after imputer: \\n\\n', X)\n",
    "# print('\\n','_'*7,'\\n')\n",
    "\n",
    "\n",
    "# ## ------- Categorical encoding ------- ##\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "print('CATEGOTICAL ENCODING \\n')\n",
    "print('X before encoding: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# Set Categorical data index\n",
    "cat_data_index = 2\n",
    "\n",
    "# Create Column Transformer object for multi-categoical \n",
    "columntransformer = ColumnTransformer([('encoder', OneHotEncoder(), [cat_data_index])], remainder='passthrough')\n",
    "\n",
    "# take a copy for mapping purposes \n",
    "X_names = X.copy()\n",
    "\n",
    "# fit to data\n",
    "X = columntransformer.fit_transform(X) \n",
    "\n",
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]\n",
    "\n",
    "# need to use drop if you want to get feature names \n",
    "columntransformer_names = ColumnTransformer([('encoder', OneHotEncoder(), [cat_data_index])], remainder='drop')\n",
    "X_names = columntransformer_names.fit_transform(X_names)\n",
    "X_mapping_vals = columntransformer_names.get_feature_names()\n",
    "\n",
    "print('X after encoding: \\n\\n', X, '\\n\\n')\n",
    "print('X mapping (col names): \\n\\n', X_mapping_vals, '\\n\\n')\n",
    "\n",
    "\n",
    "# print('y before encoding: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# # label encoder create object for binary categoical features\n",
    "# labelencoder_y = LabelEncoder()\n",
    "\n",
    "# # fit object to the data and replace categorical data\n",
    "# y  = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# # get mapping of features \n",
    "# y_mapping_vals = dict(zip(labelencoder_y.classes_, labelencoder_y.transform(labelencoder_y.classes_)))\n",
    "\n",
    "# print('y after encoding: \\n\\n', y, '\\n\\n')\n",
    "# print('y mapping: \\n\\n', y_mapping_vals, '\\n')\n",
    "# print('\\n','_'*7,'\\n')\n",
    "\n",
    "## ------- Splitting into Training and Test set ------- ##\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set the test size\n",
    "test_split = 0.2\n",
    "\n",
    "# random_state is set to ensure that same outcome each time. Would work fine without this\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, random_state = 0)\n",
    "\n",
    "print('SPLITTING DATA \\n')\n",
    "print('Training set size set at = ',1-test_split,'\\nTesting set size set at = ',test_split)\n",
    "print('\\nNumber of samples in training set = ', len(X_train))\n",
    "print('\\nNumber of samples in testing set = ', len(X_test))\n",
    "\n",
    "print('\\n\\nX Train = ', X_train)\n",
    "print('\\nX Test = ', X_test)\n",
    "print('\\ny Train = ', y_train)\n",
    "print('\\ny Test = ', y_test)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "## ------- Feature Scaling ------- ##\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Make scaling object using Standardization\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# Fit and transform to training data\n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "\n",
    "# use the same fit as the training set and transform the test set\n",
    "X_test = sc_X.transform(X_test) \n",
    "\n",
    "\n",
    "# Y scaling only needs to be done for regression not classification \n",
    "sc_y = StandardScaler()\n",
    "\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "y_train = sc_y.fit_transform(y_train)\n",
    "y_test = sc_y.transform(y_test)\n",
    "\n",
    "print('FEATURE SCALING\\n')\n",
    "print('\\nX Train = ', X_train)\n",
    "print('\\nX Test = ', X_test)\n",
    "print('\\ny Train = ', y_train)\n",
    "print('\\ny Test = ', y_test)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "####### MODELS\n",
    "\n",
    "## ------- Simple Linear Regression -------\n",
    "\n",
    "# # Remove all other variables apart from years experience for simple regression example\n",
    "# ##------- >> REMEMBER TO DELETE IF NOT NEEDED\n",
    "# X_train = X_train[:,3].reshape(-1, 1) \n",
    "# X_test = X_test[:,3].reshape(-1, 1)\n",
    "\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# regressor = LinearRegression()\n",
    "# regressor.fit(X_train, y_train)\n",
    "\n",
    "# # Predicting the Test set results\n",
    "# y_pred = regressor.predict(X_test)\n",
    "\n",
    "# # plots\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Visualising the Training set results\n",
    "# plt.scatter(X_train, y_train, color = 'red')\n",
    "# plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "# plt.title('Salary vs Experience (Training set)')\n",
    "# plt.xlabel('Years of Experience')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "# # Visualising the Test set results\n",
    "# plt.scatter(X_test, y_test, color = 'red')\n",
    "# plt.plot(X_train, regressor.predict(X_train), color = 'blue')\n",
    "# plt.title('Salary vs Experience (Test set)')\n",
    "# plt.xlabel('Years of Experience')\n",
    "# plt.ylabel('Salary')\n",
    "# plt.show()\n",
    "\n",
    "## ------- Multiple Linear Regression -------\n",
    "\n",
    "# # Remove unwanted other variables for example\n",
    "# ##------- >> REMEMBER TO DELETE IF NOT NEEDED\n",
    "X_train = np.delete(X_train, 3, 1)\n",
    "X_test = np.delete(X_test, 3, 1)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "# transform numbers back (can double check with origianl y_test)\n",
    "y_test_end = sc_y.inverse_transform(y_test)\n",
    "y_pred_end = sc_y.inverse_transform(y_pred)\n",
    "\n",
    "print(' ------- Multiple Linear Regression ------- \\n')\n",
    "print('Real: \\n', y_test_end, '\\n\\nPredicted: \\n',y_pred_end)\n",
    "# need to unscale these again \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
