{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "The Age and Salary variables (below) are not on the same scale. Feature scaling is really important for the following reason:  \n",
    "\n",
    "Most ML models are based on the Euclidean Distance (some models - like decision trees, are not based on the Euclidean Distance, however, feature scaling will allow the algorithm to converge much faster).  \n",
    "Euclidean Distance between $P1$ and $P2$ $= \\sqrt{(X2 - X1)^2 + (Y2 - Y1)^2}$\n",
    "\n",
    "Taking the data below as an example, the Euclidean Distance will be dominated by the salary.  \n",
    "Salary: $(79800 - 48000) ^2 = 961000000$  \n",
    "Age: $(48 - 27) ^2 = 441$\n",
    "\n",
    "In the model, therefore, it would be like the Age doesn't exist. To ensure that all variables are equal, they need to be in the same scale. Transformation can either be done via Standardization or Normalization. \n",
    "\n",
    "\n",
    "$Xstand = \\dfrac{x - mean(x)}{Standard Deviation (x)}$  \n",
    "  \n",
    "$Xnorm = \\dfrac{x - min(x)}{max(x) - min(x)}$  \n",
    "\n",
    "\n",
    "Needs to be done after train/test split so that the the scaling is based on the training data alone. The same fit is then used for the test data set and making future predictions.   \n",
    "\n",
    "The example here scales the categorical data that has been encoded also. If this needs to be done depends on the context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 40.0 63777.78]\n",
      " [1.0 0.0 0.0 37.0 67000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 0.0 1.0 38.77 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n",
      "[[-1.          2.64575131 -0.77459667  0.26323727  0.12381499]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.25333628  0.46175629]\n",
      " [-1.         -0.37796447  1.29099445 -1.97524812 -1.53093343]\n",
      " [-1.         -0.37796447  1.29099445  0.05144212 -1.11141981]\n",
      " [ 1.         -0.37796447 -0.77459667  1.64076674  1.72029716]\n",
      " [-1.         -0.37796447  1.29099445 -0.0811451  -0.16751415]\n",
      " [ 1.         -0.37796447 -0.77459667  0.95200201  0.98614832]\n",
      " [ 1.         -0.37796447 -0.77459667 -0.59771865 -0.48214937]]\n"
     ]
    }
   ],
   "source": [
    "## ------- Import libraries and data ------- ##\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lst = [['France', 44, 72000, 'No'], \n",
    "       ['Spain', 27, 48000, 'Yes'],\n",
    "       ['Germany', 30, 54000, 'No'],\n",
    "       ['Spain', 38, 61000, 'No'],\n",
    "       ['Germany', 40, 63777.78 , 'Yes'],\n",
    "       ['France', 35, 58000, 'Yes'],\n",
    "       ['Spain', 38.77 , 52000, 'No'],\n",
    "       ['France', 48,79000, 'Yes'],\n",
    "       ['Germany', 50, 83000, 'No'],\n",
    "       ['France', 37, 67000, 'Yes']]  \n",
    "\n",
    "df = pd.DataFrame(lst, columns =['Country', 'Age', 'Salary', 'Purchased'])\n",
    "\n",
    "# set X as all independent variables\n",
    "X = df.iloc[:,:-1].values\n",
    "\n",
    "# set y as dependent variable\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "\n",
    "## ------- Categorical encoding ------- ##\n",
    "\n",
    "\n",
    "# Create Column Transformer object for multi-categoical \n",
    "columntransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "\n",
    "# take a copy for mapping purposes \n",
    "X_names = X.copy()\n",
    "\n",
    "# fit to data\n",
    "X = columntransformer.fit_transform(X) \n",
    "\n",
    "# need to use drop if you want to get feature names \n",
    "columntransformer_names = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='drop')\n",
    "X_names = columntransformer_names.fit_transform(X_names)\n",
    "X_mapping_vals = columntransformer_names.get_feature_names()\n",
    "\n",
    "\n",
    "# label encoder create object for binary categoical features\n",
    "labelencoder_y = LabelEncoder()\n",
    "\n",
    "# fit object to the data and replace categorical data\n",
    "y  = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# get mapping of features \n",
    "y_mapping_vals = dict(zip(labelencoder_y.classes_, labelencoder_y.transform(labelencoder_y.classes_)))\n",
    "\n",
    "\n",
    "\n",
    "## ------- Splitting into Training and Test set ------- ##\n",
    "\n",
    "# random_state is set to ensure that same outcome each time. Would work fine without this\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "\n",
    "## ------- Feature Scaling ------- ##\n",
    "\n",
    "# Make scaling object using Standardization\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# Fit and transform to training data\n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "\n",
    "# use the same fit as the training set and transform the test set\n",
    "X_test = sc_X.transform(X_test) \n",
    "\n",
    "\n",
    "# Y scaling only needs to be done for regression not classification \n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[1. 1. 1. 0. 1. 0. 0. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-860be404cdc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msc_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    519\u001b[0m                     \u001b[1;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                     \u001b[1;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[1. 1. 1. 0. 1. 0. 0. 1.].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
