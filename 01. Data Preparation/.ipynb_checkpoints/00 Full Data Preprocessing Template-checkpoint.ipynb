{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTING DATA \n",
      "\n",
      "X: \n",
      "\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "\n",
      "y: \n",
      "\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n",
      "\n",
      " _______ \n",
      "\n",
      "MISSING DATA \n",
      "\n",
      "Missing values in each feature: \n",
      "\n",
      "Country      0\n",
      "Age          1\n",
      "Salary       1\n",
      "Purchased    0\n",
      "dtype: int64\n",
      "\n",
      " _______ \n",
      "\n",
      "REPLACING MISSING DATA \n",
      "\n",
      "Check X before imputer: \n",
      "\n",
      " [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]] \n",
      "\n",
      "\n",
      "Check X after imputer: \n",
      "\n",
      " [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "\n",
      " _______ \n",
      "\n",
      "CATEGOTICAL ENCODING \n",
      "\n",
      "X before encoding: \n",
      "\n",
      " [['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]] \n",
      "\n",
      "\n",
      "X after encoding: \n",
      "\n",
      " [[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]] \n",
      "\n",
      "\n",
      "X mapping (col names): \n",
      "\n",
      " ['encoder__x0_France', 'encoder__x0_Germany', 'encoder__x0_Spain'] \n",
      "\n",
      "\n",
      "y before encoding: \n",
      "\n",
      " [[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]] \n",
      "\n",
      "\n",
      "y after encoding: \n",
      "\n",
      " [0 1 0 0 1 1 0 1 0 1] \n",
      "\n",
      "\n",
      "y mapping: \n",
      "\n",
      " {'No': 0, 'Yes': 1} \n",
      "\n",
      "\n",
      " _______ \n",
      "\n",
      "SPLITTING DATA \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing Template\n",
    "\n",
    "# Created by Sofie Aspeslagh \n",
    "\n",
    "## ------- How to use ------- ##\n",
    "\n",
    "# Any steps the need to be done within the code with be annotated with:\n",
    "# ----->>\n",
    "\n",
    "# Follow the steps below to \n",
    "# Step 1 - Remove lst variable and import your own data as df\n",
    "# Step 2 - Check that the dependent variable is the last column. If not change the values for setting X and y\n",
    "# Step 3 - Check for missing data\n",
    "# Step 4 - If there is missing data, either delete rows, replace by mean or consider using other ML techniques\n",
    "# Step 5 - Encode any Categorical features. If binary use LabelEncoder, if multi-class use OneHotEncoder\n",
    "# Step 6 - Split data into train and test sets\n",
    "# Step 7 - Feature scale any numerical data (might also include encoded data)\n",
    "# Step 8 - Delete/comment any sections you haven't used\n",
    "# Step 9 - Move libraries to the top\n",
    "\n",
    "# TODO - add in print heads instead of all data\n",
    "# add in text pre processing\n",
    "# finish off prints\n",
    "# watch a cloud guru for more stuff that might need to be added in \n",
    "\n",
    "\n",
    "## ------- Import libraries and data ------- ##\n",
    "\n",
    "import pandas as pd\n",
    "# ----->> put addition libraries here \n",
    "\n",
    "lst = [['France', 44, 72000, 'No'], \n",
    "       ['Spain', 27, 48000, 'Yes'],\n",
    "       ['Germany', 30, 54000, 'No'],\n",
    "       ['Spain', 38, 61000, 'No'],\n",
    "       ['Germany', 40, None , 'Yes'],\n",
    "       ['France', 35, 58000, 'Yes'],\n",
    "       ['Spain', None , 52000, 'No'],\n",
    "       ['France', 48,79000, 'Yes'],\n",
    "       ['Germany', 50, 83000, 'No'],\n",
    "       ['France', 37, 67000, 'Yes']]  \n",
    "\n",
    "df = pd.DataFrame(lst, columns =['Country', 'Age', 'Salary', 'Purchased'])\n",
    "# ----->> remove lst and import data as df i.e df = pd.read_csv('filename.csv')\n",
    "\n",
    "# set X as all independent variables\n",
    "X = df.iloc[:,:-1].values\n",
    "\n",
    "# set y as dependent variable\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "print('IMPORTING DATA \\n')\n",
    "print('X: \\n')\n",
    "print(X)\n",
    "print('\\ny: \\n')\n",
    "print(y)\n",
    "print('\\n','_'*7,'\\n')\n",
    "# ----->> check that X and y are correct\n",
    "\n",
    "\n",
    "## ------- Detecting missing values ------- ##\n",
    "\n",
    "# detect any NaN values - keep in mind missing values may be represented in various ways. \n",
    "missing_data = df.isnull().sum()\n",
    "\n",
    "print('MISSING DATA \\n')\n",
    "print('Missing values in each feature: \\n')\n",
    "print(missing_data)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "## ------- Replace missing values by the Mean ------- ##\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "print('REPLACING MISSING DATA \\n')\n",
    "print('Check X before imputer: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# create imputer object - for more info use help(SimpleImputer)\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = 'mean')\n",
    "\n",
    "# fit object to data - take only the cols that have missing data\n",
    "imputer = imputer.fit(X[:, 1:3])\n",
    "\n",
    "# replace nan values\n",
    "X[:,1:3] = imputer.transform(X[:,1:3])\n",
    "\n",
    "print('Check X after imputer: \\n\\n', X)\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "\n",
    "\n",
    "## ------- Categorical encoding ------- ##\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "print('CATEGOTICAL ENCODING \\n')\n",
    "print('X before encoding: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# Create Column Transformer object for multi-categoical \n",
    "columntransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "\n",
    "# take a copy for mapping purposes \n",
    "X_names = X.copy()\n",
    "\n",
    "# fit to data\n",
    "X = columntransformer.fit_transform(X) \n",
    "\n",
    "# need to use drop if you want to get feature names \n",
    "columntransformer_names = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='drop')\n",
    "X_names = columntransformer_names.fit_transform(X_names)\n",
    "X_mapping_vals = columntransformer_names.get_feature_names()\n",
    "\n",
    "print('X after encoding: \\n\\n', X, '\\n\\n')\n",
    "print('X mapping (col names): \\n\\n', X_mapping_vals, '\\n\\n')\n",
    "\n",
    "\n",
    "print('y before encoding: \\n\\n', X, '\\n\\n')\n",
    "\n",
    "# label encoder create object for binary categoical features\n",
    "labelencoder_y = LabelEncoder()\n",
    "\n",
    "# fit object to the data and replace categorical data\n",
    "y  = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# get mapping of features \n",
    "y_mapping_vals = dict(zip(labelencoder_y.classes_, labelencoder_y.transform(labelencoder_y.classes_)))\n",
    "\n",
    "print('y after encoding: \\n\\n', y, '\\n\\n')\n",
    "print('y mapping: \\n\\n', y_mapping_vals, '\\n')\n",
    "print('\\n','_'*7,'\\n')\n",
    "\n",
    "## ------- Splitting into Training and Test set ------- ##\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# random_state is set to ensure that same outcome each time. Would work fine without this\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "print('SPLITTING DATA \\n')\n",
    "\n",
    "\n",
    "## ------- Feature Scaling ------- ##\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Make scaling object using Standardization\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# Fit and transform to training data\n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "\n",
    "# use the same fit as the training set and transform the test set\n",
    "X_test = sc_X.transform(X_test) \n",
    "\n",
    "\n",
    "# Y scaling only needs to be done for regression not classification \n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
