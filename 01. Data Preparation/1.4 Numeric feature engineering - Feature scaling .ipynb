{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "\n",
    "The Age and Salary variables (below) are not on the same scale. Feature scaling is really important for the following reason:  \n",
    "\n",
    "Most ML models are based on the Euclidean Distance (some models - like decision trees, are not based on the Euclidean Distance, however, feature scaling will allow the algorithm to converge much faster).  \n",
    "Euclidean Distance between $P1$ and $P2$ $= \\sqrt{(X2 - X1)^2 + (Y2 - Y1)^2}$\n",
    "\n",
    "Taking the data below as an example, the Euclidean Distance will be dominated by the salary.  \n",
    "Salary: $(79800 - 48000) ^2 = 961000000$  \n",
    "Age: $(48 - 27) ^2 = 441$\n",
    "\n",
    "In the model, therefore, it would be like the Age doesn't exist. To ensure that all variables are equal, they need to be in the same scale. Transformation can either be done via Standardization or Normalization. \n",
    "\n",
    "\n",
    "$Xstand = \\dfrac{x - mean(x)}{Standard Deviation (x)}$  \n",
    "  \n",
    "$Xnorm = \\dfrac{x - min(x)}{max(x) - min(x)}$  \n",
    "\n",
    "\n",
    "Needs to be done after train/test split so that the the scaling is based on the training data alone. The same fit is then used for the test data set and making future predictions.   \n",
    "\n",
    "The example here scales the categorical data that has been encoded also. If this needs to be done depends on the context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ------- Import libraries and data ------- ##\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "lst = [['France', 44, 72000, 'No'], \n",
    "       ['Spain', 27, 48000, 'Yes'],\n",
    "       ['Germany', 30, 54000, 'No'],\n",
    "       ['Spain', 38, 61000, 'No'],\n",
    "       ['Germany', 40, 63777.78 , 'Yes'],\n",
    "       ['France', 35, 58000, 'Yes'],\n",
    "       ['Spain', 38.77 , 52000, 'No'],\n",
    "       ['France', 48,79000, 'Yes'],\n",
    "       ['Germany', 50, 83000, 'No'],\n",
    "       ['France', 37, 67000, 'Yes']]  \n",
    "\n",
    "df = pd.DataFrame(lst, columns =['Country', 'Age', 'Salary', 'Purchased'])\n",
    "\n",
    "# set X as all independent variables\n",
    "X = df.iloc[:,:-1].values\n",
    "\n",
    "# set y as dependent variable\n",
    "y = df.iloc[:,-1].values\n",
    "\n",
    "\n",
    "## ------- Categorical encoding ------- ##\n",
    "\n",
    "\n",
    "# Create Column Transformer object for multi-categoical \n",
    "columntransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "\n",
    "# take a copy for mapping purposes \n",
    "X_names = X.copy()\n",
    "\n",
    "# fit to data\n",
    "X = columntransformer.fit_transform(X) \n",
    "\n",
    "# need to use drop if you want to get feature names \n",
    "columntransformer_names = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='drop')\n",
    "X_names = columntransformer_names.fit_transform(X_names)\n",
    "X_mapping_vals = columntransformer_names.get_feature_names()\n",
    "\n",
    "\n",
    "# label encoder create object for binary categoical features\n",
    "labelencoder_y = LabelEncoder()\n",
    "\n",
    "# fit object to the data and replace categorical data\n",
    "y  = labelencoder_y.fit_transform(y)\n",
    "\n",
    "# get mapping of features \n",
    "y_mapping_vals = dict(zip(labelencoder_y.classes_, labelencoder_y.transform(labelencoder_y.classes_)))\n",
    "\n",
    "\n",
    "\n",
    "## ------- Splitting into Training and Test set ------- ##\n",
    "\n",
    "# random_state is set to ensure that same outcome each time. Would work fine without this\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "\n",
    "## ------- Feature Scaling ------- ##\n",
    "\n",
    "# Make scaling object using Standardization\n",
    "sc_X = StandardScaler()\n",
    "\n",
    "# Fit and transform to training data\n",
    "X_train = sc_X.fit_transform(X_train) \n",
    "\n",
    "# use the same fit as the training set and transform the test set\n",
    "X_test = sc_X.transform(X_test) \n",
    "\n",
    "\n",
    "# Y scaling only needs to be done for regression not classification \n",
    "# sc_y = StandardScaler()\n",
    "# y_train = sc_y.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
